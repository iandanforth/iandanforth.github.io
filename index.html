<!DOCTYPE html>
<html lang="en-US">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <title>
            Ian Danforth - Machine Learning / AI Research, Web Development 
            and Software Engineering
        </title>
        <meta name="description" content="Personal website and portfolio of Ian 
        Danforth. Experienced software engineer now specializing in machine 
        learning and artificial intelligence.">
        <style type="text/css">
            body {
                margin: 40px auto;
                max-width: 650px;
                line-height: 1.6;
                font-size: 18px;
                color: #444;
                padding: 0 10px;
            }
            a { color: #444; }
            footer { font-size: 16px; }
            h1, h2, h3 { line-height: 1.2; }
        </style>
        <link rel="manifest" href="manifest.json" />
        <link rel='shortcut icon' type='image/x-icon' href='/favicon.ico' />
    </head>
    <body>
    <header>
        <h1>Ian Danforth</h1>
    </header>
    <hr>
    <p>
        At the end of 2017 I started studying machine learning and doing 
        related projects full time. I completed Andrew Ng's 
        <a href="https://www.coursera.org/learn/machine-learning">Machine 
        Learning Coursera course</a>, and his 
        <a href="https://www.coursera.org/specializations/deep-learning">Deep 
        Learning specialization</a> series of five 
        smaller courses. I also attended the <a href="http://course.fast.ai/">
        Fast.ai Deep Learning course</a> in person in December. I am currently
        enrolled in the Deep Reinforcement Learning Nanodegree from Udacity.
    </p>
    <p>
        Previously I was a lead software engineer at 
        <a href="https://fetchrobotics.com/">Fetch Robotics</a> where I did
        front and backend web development as well as product management.
        Before that I was briefly CEO of my own consumer robotics 
        company where we made furry robot pets. I've also written code for 
        <a href="https://numenta.com/">Numenta</a> (machine intelligence 
        research), <a href="http://www.anybots.com/">AnyBots</a> (telepresence 
        robotics), and <a href="http://www.pbworks.com/">PBWorks</a> (hosted 
        wikis).
    </p>
    <p>
        Before my technical career I earned a B.A. in Psychology from Whitman
        College and did graduate neuroscience course work with Kenneth Campbell 
        of the <a href="https://www.uottawa.ca/brain/">Brain and Mind Research 
        Institute</a>.
    </p>
    <h2>Projects</h2>
    <p>
        <strong>PyMuscle</strong> (<a href="https://github.com/iandanforth/pymuscle">github</a>) - 
        PyMuscle provides a fast motor unit based model of skeletal muscle for 
        Python. It simulates the complex per-unit relationship between 
        excitatory input and motor-unit output as well as fatigue over time.
        This complexity is generally missing from agent control today.
    </p>
    <img src="images/motor-unit-forces-by-time.png"/>
    <p>
        It is compatible with <a href="https://gym.openai.com/">OpenAI 
        Gym</a> environments and is intended to be useful for researchers in 
        the machine learning community.
    </p>

    <h2>Research Interests</h2>
    <p>
        <strong>Generalization</strong> - How do we create a <em>single</em>
        agent which can accomplish multiple tasks? What is the environment in 
        which such an agent will naturally learn component abilities which will
        enable it to repeatably gain a wide variety of skills?
    </p>
    <p>
        <strong>Muscle Control</strong> - Controlling muscles is the primary 
        way biological creatures can affect the world. These are dynamic, noisy, 
        innacurate tools which vary their properties over multiple timescales, 
        and yet biological creatures quickly develop high skill in their 
        control. I work with simulated agents rigged with muscles at various 
        levels of fidelity to explore this task which appears foundational for 
        all known intelligences.
    </p>
    <p>
        <strong>Learned Reward Signals</strong> - How do we augment 
        reinforcement learning to overcome the reward shaping problem? What are 
        the mechanisms by which an agent can learn what should constitute a 
        reward and what should not?
    </p>
    <p>
        <strong>Lifelong Learning</strong> - How do we accomplish all of the 
        above without suffering from catastrophic forgetting? 
    </p>
    <h2>Publications</h2>
    <ul>
        <li>
            Thesis - <a href='https://scholar.google.com/scholar?hl=en&as_sdt=0%2C5&q=Distinguishing+addiction+and+high+engagement+in+the+context+of+online+game+playing&btnG='>Distinguishing addiction and high engagement in the context of online game playing</a>
        </li>
    </ul>
    <h2>Connect</h2>
    <p>
        I am open to hearing about opportunities in machine learning (research 
        and applied) and web development supporting the same. While I appreciate
        the interest, I will politely decline work focused on self-driving 
        cars or military applications of ML/AI.
    </p>
    <p><strong>email</strong> - iandanforth@gmail.com</p>
    <p><strong>github</strong> - <a href="https://github.com/iandanforth">iandanforth</a></p>
    <p><strong>twitter</strong> - <a href="https://twitter.com/iandanforth">iandanforth</a></p>
    <p><strong>linkedin</strong> - <a href="https://linkedin.com/in/iandanforth">iandanforth</a></p>
    <hr>
    <footer>
        <p>
            Hosted by <a href="https://netlify.com">Netlify</a> - Page theme 
            inspired by <a href="https://twitter.com/drew_mc">Drew McConville</a>.
        </p>
    </footer>
</body>
</html>